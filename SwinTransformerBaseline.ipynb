{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true,
      "machine_shape": "hm",
      "gpuType": "A100"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "InZjc_RaH0-3"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.utils.data import DataLoader, Subset\n",
        "from tqdm import tqdm\n",
        "import numpy as np\n",
        "import math"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Helper Functions"
      ],
      "metadata": {
        "id": "ki7k328TJE9S"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def split(ids, train, val, test):\n",
        "    # proportions of train, val, test\n",
        "    assert (train+val+test == 1)\n",
        "    IDs = np.unique(ids)\n",
        "    num_ids = len(IDs)\n",
        "\n",
        "    # priority given to the test/val sets\n",
        "    test_split = math.ceil(test * num_ids)\n",
        "    val_split = math.ceil(val * num_ids)\n",
        "    train_split = num_ids - val_split - test_split\n",
        "\n",
        "    train = np.where(np.isin(ids, IDs[:train_split]))[0]\n",
        "    val = np.where(np.isin(ids, IDs[train_split:train_split+val_split]))[0]\n",
        "    test = np.where(np.isin(ids, IDs[train_split+val_split:]))[0]\n",
        "\n",
        "    return train, val, test"
      ],
      "metadata": {
        "id": "HvFTOZ7WJEpn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Connect to Drive"
      ],
      "metadata": {
        "id": "O9EDs2bAI2Wb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "from google.colab import drive\n",
        "\n",
        "# Step 1: Mount Google Drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "# Step 2: Define file path\n",
        "file_path = \"/content/drive/MyDrive/datasets/Position_task_with_dots_synchronised_min.npz\"\n",
        "\n",
        "# Step 3: Create the folder if it doesn't exist\n",
        "os.makedirs(os.path.dirname(file_path), exist_ok=True)\n",
        "\n",
        "# Step 4: Check if file exists, if not, download it\n",
        "if not os.path.exists(file_path):\n",
        "    print(\"File not found. Downloading...\")\n",
        "    !wget -O \"/content/drive/MyDrive/datasets/Position_task_with_dots_synchronised_min.npz\" \"https://osf.io/download/ge87t/\"\n",
        "else:\n",
        "    print(\"File already exists at:\", file_path)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8VQq3oqeI5NX",
        "outputId": "383baba2-3f05-4053-9ae3-ad7c0e835087"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n",
            "File already exists at: /content/drive/MyDrive/datasets/Position_task_with_dots_synchronised_min.npz\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Dataset Loader"
      ],
      "metadata": {
        "id": "c-J20X_vJRIh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from torch.utils.data import Dataset\n",
        "import torch\n",
        "import numpy as np\n",
        "\n",
        "class EEGEyeNetDataset(Dataset):\n",
        "        def __init__(self, data_file, transpose=True):\n",
        "                self.data_file = data_file\n",
        "                print('loading data...')\n",
        "                with np.load(self.data_file) as f:  # Load the data array\n",
        "                        self.trainX = f['EEG']\n",
        "                        self.trainY = f['labels']\n",
        "                # Filter data where y[:,1] is between 0 and 800 and y[:,2] is between 0 and 600\n",
        "                valid_indices = (self.trainY[:, 1] >= 0) & (self.trainY[:, 1] <= 800) & \\\n",
        "                                        (self.trainY[:, 2] >= 0) & (self.trainY[:, 2] <= 600)\n",
        "                self.trainX = self.trainX[valid_indices]\n",
        "                self.trainY = self.trainY[valid_indices]\n",
        "                if transpose:\n",
        "                        self.trainX = np.transpose(self.trainX, (0, 2, 1))[:, np.newaxis, :, :]\n",
        "                print(self.trainY)\n",
        "\n",
        "        def __getitem__(self, index):\n",
        "                # Read a single sample of data from the data array\n",
        "                X = torch.from_numpy(self.trainX[index]).float()\n",
        "                y = torch.from_numpy(self.trainY[index,1:3]).float()\n",
        "                # Return the tensor data\n",
        "                return (X,y,index)\n",
        "\n",
        "        def __len__(self):\n",
        "                # Compute the number of samples in the data array\n",
        "                return len(self.trainX)"
      ],
      "metadata": {
        "id": "9r6POjh6JSyd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "oO8hxufGrXdo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Model"
      ],
      "metadata": {
        "id": "S_o7LbZqIluZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from torch import nn\n",
        "from transformers import SwinModel, SwinConfig\n",
        "\n",
        "class EEGSwin(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "\n",
        "        # Step 1: EEG feature extractor\n",
        "        self.conv1 = nn.Conv2d(\n",
        "            in_channels=1,\n",
        "            out_channels=256,\n",
        "            kernel_size=(1, 36),\n",
        "            stride=(1, 36),\n",
        "            padding=(0,2),\n",
        "            bias=False\n",
        "        )\n",
        "        self.batchnorm1 = nn.BatchNorm2d(256, affine=False)\n",
        "\n",
        "        # Step 2: Swin Transformer configuration\n",
        "        # Set image_size = (128, 16) → Must be divisible by patch_size = (4, 4)\n",
        "        config = SwinConfig(\n",
        "            image_size=(1, 14),          # H x W\n",
        "            num_channels=256,             # Matches your input channel dimension\n",
        "            patch_size=(1, 1),           # One patch per location (non-overlapping)\n",
        "            embed_dim=96,               # Already embedded, so keep it consistent\n",
        "            depths=[2, 2, 6, 2],         # Standard Swin-Tiny config\n",
        "            num_heads=[3, 6, 12, 24],    # Number of heads per stage\n",
        "            window_size=1,               # Can be 7 if it fits into the width (14), else 1 or another divisor\n",
        "            mlp_ratio=4.0,\n",
        "            qkv_bias=True,\n",
        "            drop_path_rate=0.2\n",
        "        )\n",
        "\n",
        "        # Step 3: Swin Transformer backbone\n",
        "        self.swin = SwinModel(config)\n",
        "\n",
        "        # Step 4: Regression head for (x, y) output\n",
        "        self.regressor = nn.Sequential(\n",
        "            nn.LayerNorm(config.hidden_size),\n",
        "            nn.Linear(config.hidden_size, 128),\n",
        "            nn.ReLU(),\n",
        "            nn.Dropout(0.1),\n",
        "            nn.Linear(128, 2)  # output x, y\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        # x: [B, 1, 129, 500]\n",
        "        x = self.conv1(x)           # → [B, 256, 129, 14] (roughly)\n",
        "        x = self.batchnorm1(x)\n",
        "\n",
        "        # Resize to fixed shape divisible by patch_size & window_size\n",
        "        x = nn.functional.interpolate(x, size=(128, 16), mode='bilinear', align_corners=False)  # → [B, 256, 128, 16]\n",
        "\n",
        "        # Swin expects shape [B, C, H, W]\n",
        "        swin_output = self.swin(x).last_hidden_state  # → [B, num_patches+1, hidden_dim]\n",
        "\n",
        "        cls_token = swin_output[:, 0]  # CLS token\n",
        "\n",
        "        out = self.regressor(cls_token)  # → [B, 2]\n",
        "        return out\n"
      ],
      "metadata": {
        "id": "NXFjHXelIiI7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Config"
      ],
      "metadata": {
        "id": "xTYsW-RIIoTy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model = ViTBase()\n",
        "# EEGEyeNet = EEGEyeNetDataset(file_path)\n",
        "batch_size = 64\n",
        "n_epoch = 15\n",
        "learning_rate = 1e-4\n",
        "\n",
        "criterion = nn.MSELoss()\n",
        "\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
        "scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=6, gamma=0.1)"
      ],
      "metadata": {
        "id": "EgUNTYyKIbx6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=6, gamma=0.1)"
      ],
      "metadata": {
        "id": "Sn5k1Kvc0Bo3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install torchinfo"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "eF6FNTO7sgyQ",
        "outputId": "3922e340-841f-4a4f-e48c-6cef338d9a52"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting torchinfo\n",
            "  Downloading torchinfo-1.8.0-py3-none-any.whl.metadata (21 kB)\n",
            "Downloading torchinfo-1.8.0-py3-none-any.whl (23 kB)\n",
            "Installing collected packages: torchinfo\n",
            "Successfully installed torchinfo-1.8.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from torchinfo import summary\n",
        "summary(model, input_size=(64, 1, 129, 500))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iKEdTnkhscam",
        "outputId": "0159e0d2-f868-4b04-d170-7803718fba8d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([64, 256, 129, 14])\n",
            "torch.Size([64, 256, 128, 16])\n",
            "torch.Size([64, 256, 128, 16])\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "===================================================================================================================\n",
              "Layer (type:depth-idx)                                            Output Shape              Param #\n",
              "===================================================================================================================\n",
              "EEGSwinScratch                                                    [64, 2]                   --\n",
              "├─Conv2d: 1-1                                                     [64, 256, 129, 14]        9,216\n",
              "├─BatchNorm2d: 1-2                                                [64, 256, 129, 14]        --\n",
              "├─SwinModel: 1-3                                                  [64, 768]                 --\n",
              "│    └─SwinEmbeddings: 2-1                                        [64, 2048, 96]            --\n",
              "│    │    └─SwinPatchEmbeddings: 3-1                              [64, 2048, 96]            24,672\n",
              "│    │    └─LayerNorm: 3-2                                        [64, 2048, 96]            192\n",
              "│    │    └─Dropout: 3-3                                          [64, 2048, 96]            --\n",
              "│    └─SwinEncoder: 2-2                                           [64, 32, 768]             --\n",
              "│    │    └─ModuleList: 3-4                                       --                        27,489,738\n",
              "│    └─LayerNorm: 2-3                                             [64, 32, 768]             1,536\n",
              "│    └─AdaptiveAvgPool1d: 2-4                                     [64, 768, 1]              --\n",
              "├─Sequential: 1-4                                                 [64, 2]                   --\n",
              "│    └─LayerNorm: 2-5                                             [64, 768]                 1,536\n",
              "│    └─Linear: 2-6                                                [64, 128]                 98,432\n",
              "│    └─ReLU: 2-7                                                  [64, 128]                 --\n",
              "│    └─Dropout: 2-8                                               [64, 128]                 --\n",
              "│    └─Linear: 2-9                                                [64, 2]                   258\n",
              "===================================================================================================================\n",
              "Total params: 27,625,580\n",
              "Trainable params: 27,625,580\n",
              "Non-trainable params: 0\n",
              "Total mult-adds (Units.GIGABYTES): 63.73\n",
              "===================================================================================================================\n",
              "Input size (MB): 16.51\n",
              "Forward/backward pass size (MB): 5974.98\n",
              "Params size (MB): 110.50\n",
              "Estimated Total Size (MB): 6102.00\n",
              "==================================================================================================================="
            ]
          },
          "metadata": {},
          "execution_count": 67
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(EEGEyeNet.trainX.shape)\n",
        "print(EEGEyeNet.trainY.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zN2syofIXlll",
        "outputId": "dd4dbbf0-5f48-4543-ea46-43e1d572e618"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(21448, 1, 129, 500)\n",
            "(21448, 3)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import sys\n",
        "def train(model, optimizer):\n",
        "    '''\n",
        "        model: model to train\n",
        "        optimizer: optimizer to update weights\n",
        "        scheduler: scheduling learning rate, used when finetuning pretrained models\n",
        "    '''\n",
        "    torch.cuda.empty_cache()\n",
        "    train_indices, val_indices, test_indices = split(EEGEyeNet.trainY[:,0],0.7,0.15,0.15)  # indices for the training set\n",
        "    print('create dataloader...')\n",
        "    criterion = nn.MSELoss()\n",
        "\n",
        "    train = Subset(EEGEyeNet,indices=train_indices)\n",
        "    val = Subset(EEGEyeNet,indices=val_indices)\n",
        "    test = Subset(EEGEyeNet,indices=test_indices)\n",
        "\n",
        "    train_loader = DataLoader(train, batch_size=batch_size)\n",
        "    val_loader = DataLoader(val, batch_size=batch_size)\n",
        "    test_loader = DataLoader(test, batch_size=batch_size)\n",
        "\n",
        "    if torch.cuda.is_available():\n",
        "        gpu_id = 0  # Change this to the desired GPU ID if you have multiple GPUs\n",
        "        torch.cuda.set_device(gpu_id)\n",
        "        device = torch.device(f\"cuda:{gpu_id}\")\n",
        "    else:\n",
        "        device = torch.device(\"cpu\")\n",
        "    if torch.cuda.device_count() > 1:\n",
        "        model = nn.DataParallel(model)  # Wrap the model with DataParallel\n",
        "    print(\"HI\")\n",
        "\n",
        "    model = model.to(device)\n",
        "    criterion = criterion.to(device)\n",
        "\n",
        "    # Initialize lists to store losses\n",
        "    train_losses = []\n",
        "    val_losses = []\n",
        "    test_losses = []\n",
        "    print('training...')\n",
        "    # Train the model\n",
        "    for epoch in range(n_epoch):\n",
        "        model.train()\n",
        "        epoch_train_loss = 0.0\n",
        "\n",
        "        for i, (inputs, targets, index) in tqdm(enumerate(train_loader)):\n",
        "            # Move the inputs and targets to the GPU (if available)\n",
        "            inputs = inputs.to(device)\n",
        "            targets = targets.to(device)\n",
        "\n",
        "            # Compute the outputs and loss for the current batch\n",
        "            optimizer.zero_grad()\n",
        "            outputs = model(inputs)\n",
        "            loss = criterion(outputs.squeeze(), targets.squeeze())\n",
        "\n",
        "            # Compute the gradients and update the parameters\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "            epoch_train_loss += loss.item()\n",
        "\n",
        "            # Print the loss and accuracy for the current batch\n",
        "            if i % 100 == 0:\n",
        "                print(f\"Epoch {epoch}, Batch {i}, Loss: {loss.item()}\")\n",
        "\n",
        "        epoch_train_loss /= len(train_loader)\n",
        "        train_losses.append(epoch_train_loss)\n",
        "\n",
        "        # Evaluate the model on the validation set\n",
        "        model.eval()\n",
        "        with torch.no_grad():\n",
        "            val_loss = 0.0\n",
        "            for inputs, targets, index in val_loader:\n",
        "                # Move the inputs and targets to the GPU (if available)\n",
        "                inputs = inputs.to(device)\n",
        "                targets = targets.to(device)\n",
        "\n",
        "                # Compute the outputs and loss for the current batch\n",
        "                outputs = model(inputs)\n",
        "                # print(outputs)\n",
        "                loss = criterion(outputs.squeeze(), targets.squeeze())\n",
        "                val_loss += loss.item()\n",
        "\n",
        "\n",
        "            val_loss /= len(val_loader)\n",
        "            val_losses.append(val_loss)\n",
        "\n",
        "            print(f\"Epoch {epoch}, Val Loss: {val_loss}\")\n",
        "\n",
        "        with torch.no_grad():\n",
        "            val_loss = 0.0\n",
        "            for inputs, targets, index in test_loader:\n",
        "                # Move the inputs and targets to the GPU (if available)\n",
        "                inputs = inputs.to(device)\n",
        "                targets = targets.to(device)\n",
        "\n",
        "                # Compute the outputs and loss for the current batch\n",
        "                outputs = model(inputs)\n",
        "\n",
        "                loss = criterion(outputs.squeeze(), targets.squeeze())\n",
        "                val_loss += loss.item()\n",
        "\n",
        "            val_loss /= len(test_loader)\n",
        "            test_losses.append(val_loss)\n",
        "\n",
        "            print(f\"Epoch {epoch}, test Loss: {val_loss}\")\n",
        "\n",
        "        # if scheduler is not None:\n",
        "        #     scheduler.step()\n",
        "\n",
        "train(model, optimizer=optimizer)"
      ],
      "metadata": {
        "id": "SrvrfQhmIfmR",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "92670740-9134-4df2-9b84-77e68ffbcf9e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "create dataloader...\n",
            "HI\n",
            "training...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "2it [00:00,  6.36it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 0, Batch 0, Loss: 168953.71875\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "102it [00:15,  6.72it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 0, Batch 100, Loss: 141320.640625\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "202it [00:30,  6.68it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 0, Batch 200, Loss: 109290.765625\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "236it [00:35,  6.73it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 0, Val Loss: 99276.81457270408\n",
            "Epoch 0, test Loss: 102510.78569240196\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "1it [00:00,  6.72it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1, Batch 0, Loss: 103957.921875\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "102it [00:15,  6.74it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1, Batch 100, Loss: 65892.84375\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "202it [00:30,  6.74it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1, Batch 200, Loss: 43912.18359375\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "236it [00:34,  6.74it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1, Val Loss: 42067.19387755102\n",
            "Epoch 1, test Loss: 43107.77022058824\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "1it [00:00,  6.77it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 2, Batch 0, Loss: 43780.2421875\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "102it [00:15,  6.73it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 2, Batch 100, Loss: 39832.87890625\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "202it [00:29,  6.76it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 2, Batch 200, Loss: 34653.015625\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "236it [00:34,  6.74it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 2, Val Loss: 32371.688815369896\n",
            "Epoch 2, test Loss: 32568.79465379902\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "1it [00:00,  6.86it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 3, Batch 0, Loss: 32640.90625\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "102it [00:15,  6.78it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 3, Batch 100, Loss: 31950.80859375\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "202it [00:29,  6.74it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 3, Batch 200, Loss: 30435.466796875\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "236it [00:34,  6.75it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 3, Val Loss: 29264.857342155614\n",
            "Epoch 3, test Loss: 28937.95063572304\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "1it [00:00,  6.84it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 4, Batch 0, Loss: 28997.55078125\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "102it [00:15,  6.76it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 4, Batch 100, Loss: 30530.15625\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "202it [00:29,  6.73it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 4, Batch 200, Loss: 29217.40625\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "236it [00:34,  6.77it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 4, Val Loss: 28417.538464604593\n",
            "Epoch 4, test Loss: 27973.214116115196\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "1it [00:00,  6.83it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 5, Batch 0, Loss: 27702.3046875\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "102it [00:15,  6.80it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 5, Batch 100, Loss: 30044.91015625\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "202it [00:29,  6.73it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 5, Batch 200, Loss: 30179.4453125\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "236it [00:34,  6.79it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 5, Val Loss: 27658.463289221938\n",
            "Epoch 5, test Loss: 27208.336818321077\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "1it [00:00,  6.81it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 6, Batch 0, Loss: 27475.72265625\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "102it [00:15,  6.79it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 6, Batch 100, Loss: 27375.015625\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "202it [00:29,  6.78it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 6, Batch 200, Loss: 25996.84765625\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "236it [00:34,  6.78it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 6, Val Loss: 26202.570990114797\n",
            "Epoch 6, test Loss: 25788.845511642157\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "1it [00:00,  6.81it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 7, Batch 0, Loss: 25631.58203125\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "102it [00:15,  6.81it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 7, Batch 100, Loss: 25414.96484375\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "202it [00:29,  6.76it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 7, Batch 200, Loss: 26075.82421875\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "236it [00:34,  6.80it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 7, Val Loss: 25025.795320471938\n",
            "Epoch 7, test Loss: 24300.337239583332\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "1it [00:00,  6.75it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 8, Batch 0, Loss: 25051.1484375\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "102it [00:15,  6.73it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 8, Batch 100, Loss: 23802.658203125\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "202it [00:29,  6.80it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 8, Batch 200, Loss: 26145.9140625\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "236it [00:34,  6.78it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 8, Val Loss: 24456.245336415817\n",
            "Epoch 8, test Loss: 23537.96124387255\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "1it [00:00,  6.85it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 9, Batch 0, Loss: 23619.7421875\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "102it [00:15,  6.80it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 9, Batch 100, Loss: 24327.8125\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "202it [00:29,  6.78it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 9, Batch 200, Loss: 33815.6484375\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "236it [00:34,  6.78it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 9, Val Loss: 24884.343909438776\n",
            "Epoch 9, test Loss: 23820.26171875\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "1it [00:00,  6.82it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 10, Batch 0, Loss: 27746.435546875\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "102it [00:15,  6.78it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 10, Batch 100, Loss: 21386.12890625\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "202it [00:29,  6.80it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 10, Batch 200, Loss: 34015.7265625\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "236it [00:34,  6.78it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 10, Val Loss: 23791.287228954083\n",
            "Epoch 10, test Loss: 22924.85577512255\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "1it [00:00,  6.86it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 11, Batch 0, Loss: 25251.4296875\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "102it [00:15,  6.77it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 11, Batch 100, Loss: 23054.474609375\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "202it [00:29,  6.74it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 11, Batch 200, Loss: 32833.015625\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "236it [00:34,  6.76it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 11, Val Loss: 23808.06979432398\n",
            "Epoch 11, test Loss: 22830.021407781864\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "1it [00:00,  6.81it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 12, Batch 0, Loss: 24677.20703125\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "102it [00:15,  6.76it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 12, Batch 100, Loss: 21904.197265625\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "202it [00:29,  6.78it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 12, Batch 200, Loss: 33882.10546875\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "236it [00:34,  6.79it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 12, Val Loss: 23754.199178890307\n",
            "Epoch 12, test Loss: 22679.16988357843\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "1it [00:00,  6.67it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 13, Batch 0, Loss: 24149.19140625\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "102it [00:15,  6.75it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 13, Batch 100, Loss: 21546.154296875\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "202it [00:30,  6.74it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 13, Batch 200, Loss: 32619.4375\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "236it [00:34,  6.75it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 13, Val Loss: 23397.00031887755\n",
            "Epoch 13, test Loss: 22420.07923560049\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "1it [00:00,  6.80it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 14, Batch 0, Loss: 23283.70703125\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "102it [00:15,  6.73it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 14, Batch 100, Loss: 20158.294921875\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "202it [00:29,  6.76it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 14, Batch 200, Loss: 32745.224609375\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "236it [00:34,  6.75it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 14, Val Loss: 23195.046835140307\n",
            "Epoch 14, test Loss: 22118.709712009804\n"
          ]
        }
      ]
    }
  ]
}