{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "38e649a5",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "38e649a5",
        "outputId": "82b630ee-2071-4ac5-a251-e3f8260e1de9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using device: cuda\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import math\n",
        "import json\n",
        "import copy\n",
        "from tqdm import tqdm\n",
        "import sys\n",
        "import random\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(f\"Using device: {device}\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "from google.colab import drive\n",
        "\n",
        "# Step 1: Mount Google Drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9BbxoBCjYDFQ",
        "outputId": "366839fd-0684-42a5-d71b-b74f50bae84b"
      },
      "id": "9BbxoBCjYDFQ",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 2: Define file path\n",
        "drive_home = '/content/drive/MyDrive/'\n",
        "file_path = \"/content/drive/MyDrive/datasets/Position_task_with_dots_synchronised_min.npz\"\n",
        "\n",
        "# Step 3: Create the folder if it doesn't exist\n",
        "os.makedirs(os.path.dirname(file_path), exist_ok=True)\n",
        "\n",
        "# Step 4: Check if file exists, if not, download it\n",
        "if not os.path.exists(file_path):\n",
        "    print(\"File not found. Downloading...\")\n",
        "    !wget -O \"/content/drive/MyDrive/datasets/Position_task_with_dots_synchronised_min.npz\" \"https://osf.io/download/ge87t/\"\n",
        "else:\n",
        "    print(\"File already exists at:\", file_path)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "k98a7N06YHGn",
        "outputId": "0ea7a88a-c55a-4ef3-8d9a-9ad8a2156856"
      },
      "id": "k98a7N06YHGn",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "File already exists at: /content/drive/MyDrive/datasets/Position_task_with_dots_synchronised_min.npz\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "id": "307555cb",
      "metadata": {
        "id": "307555cb"
      },
      "source": [
        "### Load Data to Numpy Array"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "6bf19ce0",
      "metadata": {
        "id": "6bf19ce0"
      },
      "outputs": [],
      "source": [
        "data = np.load(file_path)\n",
        "\n",
        "trainX = data['EEG']\n",
        "trainY = data['labels'][:,1:] # The first column are the Id-s, the second and third are position x and y which we use\n",
        "ids = data['labels'][:, 0] # Participant Ids\n",
        "print(f\"trainX.shape: {trainX.shape}\")\n",
        "print(f\"trainY.shape: {trainY.shape}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "f383b243",
      "metadata": {
        "id": "f383b243"
      },
      "source": [
        "### Visualize"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "6ffa0417",
      "metadata": {
        "id": "6ffa0417"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "quadrants = []\n",
        "for x, y in trainY:\n",
        "    if x > 0 and y > 0:\n",
        "        quadrants.append(1)\n",
        "    elif x < 0 and y > 0:\n",
        "        quadrants.append(2)\n",
        "    elif x < 0 and y < 0:\n",
        "        quadrants.append(3)\n",
        "    elif x > 0 and y < 0:\n",
        "        quadrants.append(4)\n",
        "    else:\n",
        "        quadrants.append(0)  # On axis\n",
        "quadrants = np.array(quadrants)\n",
        "\n",
        "# Plot\n",
        "colors = ['gray', 'red', 'blue', 'green', 'purple']\n",
        "labels = ['Axis', 'Q1', 'Q2', 'Q3', 'Q4']\n",
        "\n",
        "plt.figure(figsize=(8, 8))\n",
        "for q in range(5):\n",
        "    idx = quadrants == q\n",
        "    plt.scatter(trainY[idx, 0], trainY[idx, 1], label=labels[q], alpha=0.6, s=10)\n",
        "\n",
        "plt.axhline(0, color='black', linewidth=1)\n",
        "plt.axvline(0, color='black', linewidth=1)\n",
        "plt.title(\"trainY Distribution Across 4 Quadrants\")\n",
        "plt.xlabel(\"X\")\n",
        "plt.ylabel(\"Y\")\n",
        "plt.legend()\n",
        "plt.grid(True)\n",
        "plt.axis('equal')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "1e6a149b",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1e6a149b",
        "outputId": "6282ec9b-27e7-4001-afd0-30fa5c7b9aed"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(21448, 1, 129, 500)\n",
            "(21448, 2)\n"
          ]
        }
      ],
      "source": [
        "# Filter data where trainY[:,0] is between 0 and 800 and trainY[:,1] is between 0 and 600\n",
        "valid_indices = (trainY[:, 0] >= 0) & (trainY[:, 0] <= 800) & \\\n",
        "                    (trainY[:, 1] >= 0) & (trainY[:, 1] <= 600)\n",
        "trainX = trainX[valid_indices]\n",
        "trainY = trainY[valid_indices]\n",
        "ids = ids[valid_indices]\n",
        "trainX = np.transpose(trainX, (0, 2, 1))[:, np.newaxis, :, :]\n",
        "print(trainX.shape)\n",
        "print(trainY.shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ca62a3ee",
      "metadata": {
        "id": "ca62a3ee"
      },
      "source": [
        "### After Outlier Removal"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "0a706611",
      "metadata": {
        "id": "0a706611"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "quadrants = []\n",
        "for x, y in trainY:\n",
        "    if x > 0 and y > 0:\n",
        "        quadrants.append(1)\n",
        "    elif x < 0 and y > 0:\n",
        "        quadrants.append(2)\n",
        "    elif x < 0 and y < 0:\n",
        "        quadrants.append(3)\n",
        "    elif x > 0 and y < 0:\n",
        "        quadrants.append(4)\n",
        "    else:\n",
        "        quadrants.append(0)  # On axis\n",
        "quadrants = np.array(quadrants)\n",
        "\n",
        "# Plot\n",
        "colors = ['gray', 'red', 'blue', 'green', 'purple']\n",
        "labels = ['Axis', 'Q1', 'Q2', 'Q3', 'Q4']\n",
        "\n",
        "plt.figure(figsize=(8, 8))\n",
        "for q in range(5):\n",
        "    idx = quadrants == q\n",
        "    plt.scatter(trainY[idx, 0], trainY[idx, 1], label=labels[q], alpha=0.6, s=10)\n",
        "\n",
        "plt.axhline(0, color='black', linewidth=1)\n",
        "plt.axvline(0, color='black', linewidth=1)\n",
        "plt.title(\"trainY Distribution Across 4 Quadrants\")\n",
        "plt.xlabel(\"X\")\n",
        "plt.ylabel(\"Y\")\n",
        "plt.legend()\n",
        "plt.grid(True)\n",
        "plt.axis('equal')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "d8b4b0bb",
      "metadata": {
        "id": "d8b4b0bb"
      },
      "source": [
        "### Split Data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "120b33d7",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "120b33d7",
        "outputId": "2b14bb21-1c14-4116-ee9d-fac075c5fd1c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "X_train.shape:(15071, 1, 129, 500) y_train.shape: (15071, 2)\n",
            "X_val.shape:(3132, 1, 129, 500) y_val.shape: (3132, 2)\n",
            "X_test.shape:(3245, 1, 129, 500) y_test.shape: (3245, 2)\n"
          ]
        }
      ],
      "source": [
        "import math\n",
        "import numpy as np\n",
        "\n",
        "def split(ids, train, val, test):\n",
        "    # proportions of train, val, test\n",
        "    assert (train+val+test == 1)\n",
        "    IDs = np.unique(ids)\n",
        "    num_ids = len(IDs)\n",
        "\n",
        "    # priority given to the test/val sets\n",
        "    test_split = math.ceil(test * num_ids)\n",
        "    val_split = math.ceil(val * num_ids)\n",
        "    train_split = num_ids - val_split - test_split\n",
        "\n",
        "    train = np.where(np.isin(ids, IDs[:train_split]))[0]\n",
        "    val = np.where(np.isin(ids, IDs[train_split:train_split+val_split]))[0]\n",
        "    test = np.where(np.isin(ids, IDs[train_split+val_split:]))[0]\n",
        "\n",
        "    return train, val, test\n",
        "\n",
        "train, val, test = split(ids, 0.7, 0.15, 0.15)\n",
        "X_train, y_train = trainX[train], trainY[train]\n",
        "X_val, y_val = trainX[val], trainY[val]\n",
        "X_test, y_test = trainX[test], trainY[test]\n",
        "\n",
        "print(f\"X_train.shape:{X_train.shape} y_train.shape: {y_train.shape}\")\n",
        "print(f\"X_val.shape:{X_val.shape} y_val.shape: {y_val.shape}\")\n",
        "print(f\"X_test.shape:{X_test.shape} y_test.shape: {y_test.shape}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "98112ac3",
      "metadata": {
        "id": "98112ac3"
      },
      "source": [
        "### Create DataLoaders"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c6d8ebbe",
      "metadata": {
        "id": "c6d8ebbe"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import TensorDataset, DataLoader\n",
        "\n",
        "# Convert NumPy arrays to PyTorch tensors\n",
        "X_train_tensor = torch.tensor(X_train, dtype=torch.float32)\n",
        "y_train_tensor = torch.tensor(y_train, dtype=torch.float32).unsqueeze(1)  # Shape: (N, 2)\n",
        "\n",
        "X_val_tensor = torch.tensor(X_val, dtype=torch.float32)\n",
        "y_val_tensor = torch.tensor(y_val, dtype=torch.float32).unsqueeze(1)\n",
        "\n",
        "X_test_tensor = torch.tensor(X_test, dtype=torch.float32)\n",
        "y_test_tensor = torch.tensor(y_test, dtype=torch.float32).unsqueeze(1)\n",
        "\n",
        "# Create DataLoaders\n",
        "batch_size = 64\n",
        "train_loader = DataLoader(TensorDataset(X_train_tensor, y_train_tensor), batch_size=batch_size, shuffle=True)\n",
        "val_loader = DataLoader(TensorDataset(X_val_tensor, y_val_tensor), batch_size=batch_size)\n",
        "test_loader = DataLoader(TensorDataset(X_test_tensor, y_test_tensor), batch_size=batch_size)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ae9d2c6f",
      "metadata": {
        "id": "ae9d2c6f"
      },
      "source": [
        "### Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "6e8f5e3b",
      "metadata": {
        "id": "6e8f5e3b"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import transformers\n",
        "from transformers import ViTModel\n",
        "import torch\n",
        "from torch import nn\n",
        "import transformers\n",
        "\n",
        "class EEGViT_pretrained(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        self.conv1 = nn.Conv2d(\n",
        "            in_channels=1,\n",
        "            out_channels=256,\n",
        "            kernel_size=(1, 36),\n",
        "            stride=(1, 36),\n",
        "            padding=(0,2),\n",
        "            bias=False\n",
        "        )\n",
        "        self.batchnorm1 = nn.BatchNorm2d(256, False)\n",
        "        model_name = \"google/vit-base-patch16-224\"\n",
        "        config = transformers.ViTConfig.from_pretrained(model_name)\n",
        "        config.update({'num_channels': 256})\n",
        "        config.update({'image_size': (129,14)})\n",
        "        config.update({'patch_size': (8,1)})\n",
        "\n",
        "        model = transformers.ViTForImageClassification.from_pretrained(model_name, config=config, ignore_mismatched_sizes=True)\n",
        "        model.vit.embeddings.patch_embeddings.projection = torch.nn.Conv2d(256, 768, kernel_size=(8, 1), stride=(8, 1), padding=(0,0), groups=256)\n",
        "        model.classifier=torch.nn.Sequential(torch.nn.Linear(768,1000,bias=True),\n",
        "                                     torch.nn.Dropout(p=0.1),\n",
        "                                     torch.nn.Linear(1000,2,bias=True))\n",
        "        self.ViT = model\n",
        "\n",
        "    def forward(self,x):\n",
        "        x=self.conv1(x)\n",
        "        x=self.batchnorm1(x)\n",
        "        x=self.ViT.forward(x).logits\n",
        "\n",
        "        return x"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "bbb77a8b",
      "metadata": {
        "id": "bbb77a8b"
      },
      "source": [
        "### Config"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3daecb72",
      "metadata": {
        "id": "3daecb72"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "\n",
        "class MeanEuclideanDistance(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(MeanEuclideanDistance, self).__init__()\n",
        "\n",
        "    def forward(self, y_pred, y_true):\n",
        "        return torch.mean(torch.linalg.norm(torch.sub(y_true, y_pred), dim=1))"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Set Seed\n",
        "def set_seed(seed=42):\n",
        "    random.seed(seed)\n",
        "    np.random.seed(seed)\n",
        "    torch.manual_seed(seed)\n",
        "    torch.cuda.manual_seed(seed)\n",
        "    torch.cuda.manual_seed_all(seed)  # if using multi-GPU\n",
        "\n",
        "set_seed(42)\n"
      ],
      "metadata": {
        "id": "IepVJk2L5yaO"
      },
      "id": "IepVJk2L5yaO",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a7b3494d",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a7b3494d",
        "outputId": "920619ef-26fa-4b50-c89d-dcbf453bc423"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of ViTForImageClassification were not initialized from the model checkpoint at google/vit-base-patch16-224 and are newly initialized because the shapes did not match:\n",
            "- vit.embeddings.patch_embeddings.projection.weight: found shape torch.Size([768, 3, 16, 16]) in the checkpoint and torch.Size([768, 256, 8, 1]) in the model instantiated\n",
            "- vit.embeddings.position_embeddings: found shape torch.Size([1, 197, 768]) in the checkpoint and torch.Size([1, 225, 768]) in the model instantiated\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        }
      ],
      "source": [
        "model = EEGViT_pretrained()\n",
        "\n",
        "# Load the saved state dict\n",
        "checkpoint = torch.load(\"/content/drive/MyDrive/trained_models/encoder_weights_direction_task.pt\")\n",
        "\n",
        "# Get the current model's state dict\n",
        "model_dict = model.state_dict()\n",
        "\n",
        "# Filter out keys that belong to ViT only\n",
        "vit_weights = {k: v for k, v in checkpoint.items() if k.startswith('ViT.')}\n",
        "\n",
        "# Update model's state dict with only ViT weights\n",
        "model_dict.update(vit_weights)\n",
        "model.load_state_dict(model_dict)\n",
        "\n",
        "# Check which parts are trainable\n",
        "# for name, param in model.named_parameters():\n",
        "#     print(f\"{name} requires_grad = {param.requires_grad}\")\n",
        "\n",
        "\n",
        "batch_size = 64\n",
        "n_epoch = 15\n",
        "learning_rate = 1e-4\n",
        "\n",
        "criterion = nn.MSELoss()\n",
        "\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
        "scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=6, gamma=0.1)\n",
        "\n",
        "torch.cuda.empty_cache()\n",
        "if torch.cuda.is_available():\n",
        "    gpu_id = 0  # Change this to the desired GPU ID if you have multiple GPUs\n",
        "    torch.cuda.set_device(gpu_id)\n",
        "    device = torch.device(f\"cuda:{gpu_id}\")\n",
        "else:\n",
        "    device = torch.device(\"cpu\")\n",
        "if torch.cuda.device_count() > 1:\n",
        "    print(\"Multiple GPUs Available\")\n",
        "    model = nn.DataParallel(model)  # Wrap the model with DataParallel\n",
        "\n",
        "model = model.to(device)\n",
        "criterion = criterion.to(device)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "674624f7",
      "metadata": {
        "id": "674624f7"
      },
      "source": [
        "### Training"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "145e75eb",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "145e75eb",
        "outputId": "268afe47-616d-4902-d0d7-adae95cd2f5d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "training...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 0/15: 236it [01:56,  2.03it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 0, Train Loss: 26175.6750, RMSE: 161.7890\n",
            "Epoch 0, Val Loss: 19018.2867\n",
            "Epoch 0, Test Loss (MSE): 16653.0510, RMSE: 129.0467\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 1/15: 236it [01:56,  2.02it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1, Train Loss: 18296.4746, RMSE: 135.2645\n",
            "Epoch 1, Val Loss: 18411.7602\n",
            "Epoch 1, Test Loss (MSE): 15160.2576, RMSE: 123.1270\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 2/15: 236it [01:56,  2.02it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 2, Train Loss: 16432.1804, RMSE: 128.1881\n",
            "Epoch 2, Val Loss: 18261.9425\n",
            "Epoch 2, Test Loss (MSE): 15456.6580, RMSE: 124.3248\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 3/15: 236it [01:56,  2.02it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 3, Train Loss: 15709.4877, RMSE: 125.3375\n",
            "Epoch 3, Val Loss: 16428.8419\n",
            "Epoch 3, Test Loss (MSE): 13370.9353, RMSE: 115.6328\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 4/15: 236it [01:56,  2.02it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 4, Train Loss: 14723.5241, RMSE: 121.3405\n",
            "Epoch 4, Val Loss: 18497.2147\n",
            "Epoch 4, Test Loss (MSE): 15272.7162, RMSE: 123.5828\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 5/15: 236it [01:56,  2.02it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 5, Train Loss: 13587.7986, RMSE: 116.5667\n",
            "Epoch 5, Val Loss: 16806.3903\n",
            "Epoch 5, Test Loss (MSE): 13262.4611, RMSE: 115.1628\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 6/15: 236it [01:57,  2.02it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 6, Train Loss: 11213.2569, RMSE: 105.8927\n",
            "Epoch 6, Val Loss: 16490.7170\n",
            "Epoch 6, Test Loss (MSE): 12839.2260, RMSE: 113.3103\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 7/15: 236it [01:57,  2.02it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 7, Train Loss: 10355.9040, RMSE: 101.7640\n",
            "Epoch 7, Val Loss: 16636.9557\n",
            "Epoch 7, Test Loss (MSE): 13034.6936, RMSE: 114.1696\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 8/15: 236it [01:56,  2.02it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 8, Train Loss: 9747.9310, RMSE: 98.7316\n",
            "Epoch 8, Val Loss: 16641.3889\n",
            "Epoch 8, Test Loss (MSE): 13279.7555, RMSE: 115.2378\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 9/15: 236it [01:57,  2.02it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 9, Train Loss: 9273.4044, RMSE: 96.2985\n",
            "Epoch 9, Val Loss: 16983.9535\n",
            "Epoch 9, Test Loss (MSE): 13477.2005, RMSE: 116.0913\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 10/15: 236it [01:57,  2.02it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 10, Train Loss: 8664.1676, RMSE: 93.0815\n",
            "Epoch 10, Val Loss: 17214.5759\n",
            "Epoch 10, Test Loss (MSE): 13929.4198, RMSE: 118.0230\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 11/15: 236it [01:57,  2.02it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 11, Train Loss: 8066.4877, RMSE: 89.8136\n",
            "Epoch 11, Val Loss: 17405.1405\n",
            "Epoch 11, Test Loss (MSE): 14100.2522, RMSE: 118.7445\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 12/15: 236it [01:57,  2.02it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 12, Train Loss: 7331.7094, RMSE: 85.6254\n",
            "Epoch 12, Val Loss: 17609.5500\n",
            "Epoch 12, Test Loss (MSE): 14057.3775, RMSE: 118.5638\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 13/15: 236it [01:57,  2.02it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 13, Train Loss: 7231.9425, RMSE: 85.0408\n",
            "Epoch 13, Val Loss: 17782.2136\n",
            "Epoch 13, Test Loss (MSE): 14025.6345, RMSE: 118.4299\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 14/15: 236it [01:57,  2.02it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 14, Train Loss: 7151.0008, RMSE: 84.5636\n",
            "Epoch 14, Val Loss: 17897.3158\n",
            "Epoch 14, Test Loss (MSE): 14466.7253, RMSE: 120.2777\n",
            "Best model loaded with val loss: 16428.841876594386\n",
            "Best model saved as 'abs_pos_EEGViT_OnlyVitWeightsPretrained.pt'.\n"
          ]
        }
      ],
      "source": [
        "# Initialize lists to store losses\n",
        "train_losses = []\n",
        "val_losses = []\n",
        "test_losses = []\n",
        "best_val_loss = float('inf')\n",
        "best_model_wts = None\n",
        "\n",
        "print('training...')\n",
        "# Train the model\n",
        "for epoch in range(n_epoch):\n",
        "    model.train()\n",
        "    epoch_train_loss = 0.0\n",
        "\n",
        "    for i, (inputs, targets) in tqdm(enumerate(train_loader), desc=f\"Epoch {epoch}/{n_epoch}\"):\n",
        "        # inputs = inputs.to(device).unsqueeze(1).permute(0, 1, 3, 2)\n",
        "        inputs = inputs.to(device)\n",
        "        targets = targets.to(device)\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        outputs = model(inputs)\n",
        "        loss = criterion(outputs.squeeze(), targets.squeeze())\n",
        "\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        epoch_train_loss += loss.item()\n",
        "\n",
        "        # Optional: print loss every 100 batches\n",
        "        # if i % 100 == 0:\n",
        "        #     print(f\"Epoch {epoch}, Batch {i}, Loss: {loss.item()}\")\n",
        "\n",
        "    epoch_train_loss /= len(train_loader)\n",
        "    train_losses.append(epoch_train_loss)\n",
        "    print(f\"Epoch {epoch}, Train Loss: {epoch_train_loss:.4f}, RMSE: {(epoch_train_loss ** 0.5)/2:.4f}\")\n",
        "\n",
        "    # Validation\n",
        "    model.eval()\n",
        "    val_loss = 0.0\n",
        "    with torch.no_grad():\n",
        "        for inputs, targets in val_loader:\n",
        "            inputs = inputs.to(device)\n",
        "            targets = targets.to(device)\n",
        "\n",
        "            outputs = model(inputs)\n",
        "            loss = criterion(outputs.squeeze(), targets.squeeze())\n",
        "            val_loss += loss.item()\n",
        "\n",
        "        val_loss /= len(val_loader)\n",
        "        val_losses.append(val_loss)\n",
        "        print(f\"Epoch {epoch}, Val Loss: {val_loss:.4f}\")\n",
        "\n",
        "        # Save best model based on val loss\n",
        "        if val_loss < best_val_loss:\n",
        "            best_val_loss = val_loss\n",
        "            best_model_wts = copy.deepcopy(model.state_dict())\n",
        "\n",
        "    # Test\n",
        "    test_loss = 0.0\n",
        "    with torch.no_grad():\n",
        "        for inputs, targets in test_loader:\n",
        "            inputs = inputs.to(device)\n",
        "            targets = targets.to(device)\n",
        "\n",
        "            outputs = model(inputs)\n",
        "            loss = criterion(outputs.squeeze(), targets.squeeze())\n",
        "            test_loss += loss.item()\n",
        "\n",
        "        test_loss /= len(test_loader)\n",
        "        test_losses.append(test_loss)\n",
        "        rmse = (test_loss ** 0.5)/2\n",
        "        print(f\"Epoch {epoch}, Test Loss (MSE): {test_loss:.4f}, RMSE: {rmse:.4f}\")\n",
        "\n",
        "    if scheduler is not None:\n",
        "        scheduler.step()\n",
        "\n",
        "# Load best model weights\n",
        "if best_model_wts is not None:\n",
        "    model.load_state_dict(best_model_wts)\n",
        "    print(\"Best model loaded with val loss:\", best_val_loss)\n",
        "\n",
        "# Save best model\n",
        "torch.save(model.state_dict(), \"/content/drive/MyDrive/trained_models/abs_pos_EEGViT_OnlyVitWeightsPretrained.pt\")\n",
        "print(\"Best model saved as 'abs_pos_EEGViT_OnlyVitWeightsPretrained.pt'.\")\n",
        "\n",
        "loss_dict = {\n",
        "    \"train_losses\": train_losses,\n",
        "    \"val_losses\": val_losses,\n",
        "    \"test_losses\": test_losses\n",
        "}\n",
        "\n",
        "with open(\"/content/drive/MyDrive/trained_models/loss_logs_abs_pos_EEGViT_OnlyVitWeightsPretrained.json\", \"w\") as f:\n",
        "    json.dump(loss_dict, f, indent=2)"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.1"
    },
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "gpuType": "A100"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 5
}