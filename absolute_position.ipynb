{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "38e649a5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import math\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Using device: {device}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "307555cb",
   "metadata": {},
   "source": [
    "### Load Data to Numpy Array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "6bf19ce0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<>:1: SyntaxWarning: invalid escape sequence '\\P'\n",
      "<>:1: SyntaxWarning: invalid escape sequence '\\P'\n",
      "C:\\Users\\Aniket Konkar\\AppData\\Local\\Temp\\ipykernel_3900\\1655053973.py:1: SyntaxWarning: invalid escape sequence '\\P'\n",
      "  data = np.load('data\\Position_task_with_dots_synchronised_min.npz')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trainX.shape: (21464, 500, 129)\n",
      "trainY.shape: (21464, 2)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([408.1, 315.1])"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = np.load('data\\Position_task_with_dots_synchronised_min.npz')\n",
    "\n",
    "trainX = data['EEG']\n",
    "trainY = data['labels'][:,1:] # The first column are the Id-s, the second and third are position x and y which we use\n",
    "ids = data['labels'][:, 0] # Participant Ids\n",
    "print(f\"trainX.shape: {trainX.shape}\")\n",
    "print(f\"trainY.shape: {trainY.shape}\")\n",
    "trainY[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8b4b0bb",
   "metadata": {},
   "source": [
    "### Split Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "120b33d7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train.shape:(15076, 500, 129) y_train.shape: (15076, 2)\n",
      "X_val.shape:(3134, 500, 129) y_val.shape: (3134, 2)\n",
      "X_test.shape:(3254, 500, 129) y_test.shape: (3254, 2)\n"
     ]
    }
   ],
   "source": [
    "import math\n",
    "import numpy as np\n",
    "\n",
    "def split(ids, train, val, test):\n",
    "    # proportions of train, val, test\n",
    "    assert (train+val+test == 1)\n",
    "    IDs = np.unique(ids)\n",
    "    num_ids = len(IDs)\n",
    "\n",
    "    # priority given to the test/val sets\n",
    "    test_split = math.ceil(test * num_ids)\n",
    "    val_split = math.ceil(val * num_ids)\n",
    "    train_split = num_ids - val_split - test_split\n",
    "\n",
    "    train = np.where(np.isin(ids, IDs[:train_split]))[0]\n",
    "    val = np.where(np.isin(ids, IDs[train_split:train_split+val_split]))[0]\n",
    "    test = np.where(np.isin(ids, IDs[train_split+val_split:]))[0]\n",
    "    \n",
    "    return train, val, test\n",
    "\n",
    "train, val, test = split(ids, 0.7, 0.15, 0.15)\n",
    "X_train, y_train = trainX[train], trainY[train]\n",
    "X_val, y_val = trainX[val], trainY[val]\n",
    "X_test, y_test = trainX[test], trainY[test]\n",
    "\n",
    "print(f\"X_train.shape:{X_train.shape} y_train.shape: {y_train.shape}\")\n",
    "print(f\"X_val.shape:{X_val.shape} y_val.shape: {y_val.shape}\")\n",
    "print(f\"X_test.shape:{X_test.shape} y_test.shape: {y_test.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98112ac3",
   "metadata": {},
   "source": [
    "### Create DataLoaders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "c6d8ebbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "\n",
    "# Convert NumPy arrays to PyTorch tensors\n",
    "X_train_tensor = torch.tensor(X_train, dtype=torch.float32)\n",
    "y_train_tensor = torch.tensor(y_train, dtype=torch.float32).unsqueeze(1)  # Shape: (N, 2)\n",
    "\n",
    "X_val_tensor = torch.tensor(X_val, dtype=torch.float32)\n",
    "y_val_tensor = torch.tensor(y_val, dtype=torch.float32).unsqueeze(1)\n",
    "\n",
    "X_test_tensor = torch.tensor(X_test, dtype=torch.float32)\n",
    "y_test_tensor = torch.tensor(y_test, dtype=torch.float32).unsqueeze(1)\n",
    "\n",
    "# Create DataLoaders\n",
    "batch_size = 64\n",
    "train_loader = DataLoader(TensorDataset(X_train_tensor, y_train_tensor), batch_size=batch_size, shuffle=True)\n",
    "val_loader = DataLoader(TensorDataset(X_val_tensor, y_val_tensor), batch_size=batch_size)\n",
    "test_loader = DataLoader(TensorDataset(X_test_tensor, y_test_tensor), batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae9d2c6f",
   "metadata": {},
   "source": [
    "### Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "60c6d5c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import sys\n",
    "\n",
    "class EEGEncoderRaw(nn.Module):\n",
    "    def __init__(self, pretrained_encoder_encoder):\n",
    "        super().__init__()\n",
    "\n",
    "        # Step 1: Temporal Convolution (1 x 36 kernel across time)\n",
    "        self.conv_temporal = nn.Conv2d(\n",
    "            in_channels=1, \n",
    "            out_channels=129,\n",
    "            kernel_size=(1, 36),\n",
    "            stride=(1, 36),\n",
    "            padding=(0, 2),\n",
    "            bias=False\n",
    "        )\n",
    "        self.batchnorm_temporal = nn.BatchNorm2d(129, affine=False)\n",
    "\n",
    "        # Step 2: Depthwise Spatial Convolution (8 x 1 kernel over channels)\n",
    "        self.conv_spatial = nn.Conv2d(\n",
    "            in_channels=129,\n",
    "            out_channels=129,\n",
    "            kernel_size=(8, 1),\n",
    "            stride=(8, 1),\n",
    "            groups=129,  # depthwise\n",
    "            bias=False\n",
    "        )\n",
    "        self.batchnorm_spatial = nn.BatchNorm2d(129, affine=False)\n",
    "\n",
    "        # Transformer encoder expects d_model = 129\n",
    "        self.encoder = pretrained_encoder_encoder\n",
    "\n",
    "        # Simple regression head\n",
    "        self.regressor = nn.Sequential(\n",
    "            nn.Linear(129, 128),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(128, 2)  # Predict (x, y)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        #print(f\"Input x.shape: {x.shape}\")  # [B, 1, C, T]\n",
    "\n",
    "        x = self.conv_temporal(x)\n",
    "        # print(f\"After conv_temporal: {x.shape}\")  # [B, 129, C, T']\n",
    "\n",
    "        x = self.batchnorm_temporal(x)\n",
    "        # print(f\"After batchnorm_temporal: {x.shape}\")\n",
    "\n",
    "        x = self.conv_spatial(x)\n",
    "        # print(f\"After conv_spatial: {x.shape}\")  # [B, 129, H', W']\n",
    "\n",
    "        x = self.batchnorm_spatial(x)\n",
    "        # print(f\"After batchnorm_spatial: {x.shape}\")\n",
    "\n",
    "        B, C, H, W = x.shape\n",
    "        x = x.view(B, C, -1).permute(0, 2, 1)  # [B, seq_len, 129]\n",
    "        # print(f\"After view & permute: {x.shape}\")\n",
    "\n",
    "        x = self.encoder(x)\n",
    "        # print(f\"After transformer encoder: {x.shape}\")  # [B, seq_len, 129]\n",
    "\n",
    "        pooled = x.mean(dim=1)\n",
    "        # print(f\"After mean pooling: {pooled.shape}\")  # [B, 129]\n",
    "\n",
    "        coords = self.regressor(pooled)\n",
    "        # print(f\"Output coords: {coords.shape}\")  # [B, 2]\n",
    "        # sys.exit()\n",
    "        return coords\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "de5e3d31",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_pretrained_transformer_encoder():\n",
    "    encoder_layer = nn.TransformerEncoderLayer(\n",
    "        d_model=129,          # same as input_dim\n",
    "        nhead=3,\n",
    "        dim_feedforward=512,\n",
    "        batch_first=True\n",
    "    )\n",
    "    transformer_encoder = nn.TransformerEncoder(encoder_layer, num_layers=2)\n",
    "    transformer_encoder.load_state_dict(torch.load(\"pretrained_encoder.pt\"))\n",
    "    return transformer_encoder\n",
    "\n",
    "\n",
    "batch_size = 64\n",
    "n_epoch = 15\n",
    "learning_rate = 1e-4\n",
    "# Recreate the encoder.encoder module (must match architecture used in training)\n",
    "pretrained_encoder_encoder = get_pretrained_transformer_encoder()\n",
    "\n",
    "# Create model\n",
    "model = EEGEncoderRaw(pretrained_encoder_encoder)\n",
    "criterion = nn.MSELoss()\n",
    "\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
    "scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=6, gamma=0.1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "674624f7",
   "metadata": {},
   "source": [
    "### Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "040821a5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 0/15: 236it [00:05, 39.83it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0, Train Loss: 36608.2921\n",
      "Epoch 0, Val Loss: 36629.5651\n",
      "Epoch 0, Test Loss (MSE): 37566.8305, RMSE: 193.8216\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/15: 236it [00:05, 42.16it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Train Loss: 36588.3983\n",
      "Epoch 1, Val Loss: 36607.3192\n",
      "Epoch 1, Test Loss (MSE): 37540.3856, RMSE: 193.7534\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2/15: 236it [00:05, 42.36it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2, Train Loss: 36579.5176\n",
      "Epoch 2, Val Loss: 36584.4030\n",
      "Epoch 2, Test Loss (MSE): 37513.0541, RMSE: 193.6829\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3/15: 236it [00:05, 42.26it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3, Train Loss: 36557.9608\n",
      "Epoch 3, Val Loss: 36582.8209\n",
      "Epoch 3, Test Loss (MSE): 37510.4892, RMSE: 193.6762\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 4/15: 236it [00:05, 42.20it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4, Train Loss: 36572.7492\n",
      "Epoch 4, Val Loss: 36580.1362\n",
      "Epoch 4, Test Loss (MSE): 37507.5886, RMSE: 193.6688\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 5/15: 236it [00:05, 42.09it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5, Train Loss: 36548.9888\n",
      "Epoch 5, Val Loss: 36577.4642\n",
      "Epoch 5, Test Loss (MSE): 37504.8498, RMSE: 193.6617\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 6/15: 236it [00:05, 41.78it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6, Train Loss: 36565.2146\n",
      "Epoch 6, Val Loss: 36575.5962\n",
      "Epoch 6, Test Loss (MSE): 37501.8849, RMSE: 193.6540\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 7/15: 236it [00:05, 42.04it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7, Train Loss: 36558.2975\n",
      "Epoch 7, Val Loss: 36571.9887\n",
      "Epoch 7, Test Loss (MSE): 37498.6473, RMSE: 193.6457\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 8/15: 236it [00:05, 41.57it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8, Train Loss: 36547.6038\n",
      "Epoch 8, Val Loss: 36569.3184\n",
      "Epoch 8, Test Loss (MSE): 37495.5831, RMSE: 193.6378\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 9/15: 236it [00:05, 41.73it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9, Train Loss: 36547.1070\n",
      "Epoch 9, Val Loss: 36570.1582\n",
      "Epoch 9, Test Loss (MSE): 37495.5486, RMSE: 193.6377\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 10/15: 236it [00:05, 41.99it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10, Train Loss: 36553.9963\n",
      "Epoch 10, Val Loss: 36569.6699\n",
      "Epoch 10, Test Loss (MSE): 37495.2926, RMSE: 193.6370\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 11/15: 236it [00:05, 41.76it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 11, Train Loss: 36540.7189\n",
      "Epoch 11, Val Loss: 36569.1493\n",
      "Epoch 11, Test Loss (MSE): 37494.9010, RMSE: 193.6360\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 12/15: 236it [00:05, 42.03it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 12, Train Loss: 36549.5697\n",
      "Epoch 12, Val Loss: 36569.0646\n",
      "Epoch 12, Test Loss (MSE): 37494.6138, RMSE: 193.6353\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 13/15: 236it [00:05, 41.95it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 13, Train Loss: 36529.4564\n",
      "Epoch 13, Val Loss: 36569.1344\n",
      "Epoch 13, Test Loss (MSE): 37494.3856, RMSE: 193.6347\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 14/15: 236it [00:05, 42.11it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 14, Train Loss: 36531.6994\n",
      "Epoch 14, Val Loss: 36567.9583\n",
      "Epoch 14, Test Loss (MSE): 37494.0500, RMSE: 193.6338\n",
      "Best model loaded with val loss: 36567.9583466199\n",
      "Best model saved as 'best_model_abs_pos.pt'.\n",
      "Encoder weights saved as 'encoder_weights_abs_pos.pt'.\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import copy\n",
    "from tqdm import tqdm\n",
    "import sys\n",
    "\n",
    "torch.cuda.empty_cache()\n",
    "model = model.to(device)\n",
    "criterion = criterion.to(device)\n",
    "\n",
    "# Initialize lists to store losses\n",
    "train_losses = []\n",
    "val_losses = []\n",
    "test_losses = []\n",
    "best_val_loss = float('inf')\n",
    "best_model_wts = None\n",
    "\n",
    "print('Training...')\n",
    "\n",
    "# Train the model\n",
    "for epoch in range(n_epoch):\n",
    "    model.train()\n",
    "    epoch_train_loss = 0.0\n",
    "\n",
    "    for i, (inputs, targets) in tqdm(enumerate(train_loader), desc=f\"Epoch {epoch}/{n_epoch}\"):\n",
    "        inputs = inputs.to(device).unsqueeze(1).permute(0, 1, 3, 2)\n",
    "        targets = targets.to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(inputs)\n",
    "        loss = criterion(outputs.squeeze(), targets.squeeze())\n",
    "\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        epoch_train_loss += loss.item()\n",
    "\n",
    "        # Optional: print loss every 5 batches\n",
    "        # if i % 5 == 0:\n",
    "        #     print(f\"Epoch {epoch}, Batch {i}, Loss: {loss.item()}\")\n",
    "\n",
    "    epoch_train_loss /= len(train_loader)\n",
    "    train_losses.append(epoch_train_loss)\n",
    "    print(f\"Epoch {epoch}, Train Loss: {epoch_train_loss:.4f}\")\n",
    "\n",
    "    # Validation\n",
    "    model.eval()\n",
    "    val_loss = 0.0\n",
    "    with torch.no_grad():\n",
    "        for inputs, targets in val_loader:\n",
    "            inputs = inputs.to(device).unsqueeze(1).permute(0, 1, 3, 2)\n",
    "            targets = targets.to(device)\n",
    "\n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs.squeeze(), targets.squeeze())\n",
    "            val_loss += loss.item()\n",
    "\n",
    "        val_loss /= len(val_loader)\n",
    "        val_losses.append(val_loss)\n",
    "        print(f\"Epoch {epoch}, Val Loss: {val_loss:.4f}\")\n",
    "\n",
    "        # Save best model based on val loss\n",
    "        if val_loss < best_val_loss:\n",
    "            best_val_loss = val_loss\n",
    "            best_model_wts = copy.deepcopy(model.state_dict())\n",
    "\n",
    "    # Test\n",
    "    test_loss = 0.0\n",
    "    with torch.no_grad():\n",
    "        for inputs, targets in test_loader:\n",
    "            inputs = inputs.to(device).unsqueeze(1).permute(0, 1, 3, 2)\n",
    "            targets = targets.to(device)\n",
    "\n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs.squeeze(), targets.squeeze())\n",
    "            test_loss += loss.item()\n",
    "\n",
    "        test_loss /= len(test_loader)\n",
    "        test_losses.append(test_loss)\n",
    "        rmse = test_loss ** 0.5\n",
    "        print(f\"Epoch {epoch}, Test Loss (MSE): {test_loss:.4f}, RMSE: {rmse:.4f}\")\n",
    "\n",
    "    if scheduler is not None:\n",
    "        scheduler.step()\n",
    "\n",
    "# Load best model weights\n",
    "if best_model_wts is not None:\n",
    "    model.load_state_dict(best_model_wts)\n",
    "    print(\"Best model loaded with val loss:\", best_val_loss)\n",
    "\n",
    "# Save best model\n",
    "torch.save(model.state_dict(), \"best_model_abs_pos.pt\")\n",
    "print(\"Best model saved as 'best_model_abs_pos.pt'.\")\n",
    "\n",
    "# Save encoder weights\n",
    "if hasattr(model, 'encoder'):\n",
    "    torch.save(model.encoder.state_dict(), \"encoder_weights_abs_pos.pt\")\n",
    "    print(\"Encoder weights saved as 'encoder_weights_abs_pos.pt'.\")\n",
    "else:\n",
    "    print(\"Model does not have an 'encoder' attribute to save.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
